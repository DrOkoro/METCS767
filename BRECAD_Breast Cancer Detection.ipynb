{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.metrics import Recall\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set appropriate style for all plots\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataset from a csv file into a pandas dataframe\n",
    "breast_cancer = pd.read_csv('wbcd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the first 5 rows\n",
    "breast_cancer.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = breast_cancer.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Drop the id column as it serves no purposes with respect to classification\n",
    "breast_cancer.drop([cols[-1], cols[0]], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = cols[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the aggregate below, there are 357 benign records and 212 malignant records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_values = list(breast_cancer['diagnosis'].value_counts().keys())\n",
    "breast_cancer['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable must be categorical with only 2 possible values: 'M' and 'B'\n",
    "if (len(target_values)==2 and ('B' in target_values) and ('M' in target_values)):\n",
    "    print('Target Variable is in the Correct Format.')\n",
    "else:\n",
    "    print('Error! Please Verify The Dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(breast_cancer['diagnosis'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer['area_se'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cols[1:]:\n",
    "    if breast_cancer[i].dtype != np.float64:\n",
    "        print('Error! Please Verify The Dataset.')\n",
    "else:\n",
    "    print('All Features are in the Correct Format')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in cols[1:]:\n",
    "    if breast_cancer[k].min() < 0:\n",
    "        print('Error! Please Verify The Dataset.')\n",
    "else:\n",
    "    print('All Features are in the Correct Format')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = breast_cancer[cols[1:]]\n",
    "features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target = breast_cancer['diagnosis']\n",
    "target[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,15))\n",
    "\n",
    "for i,j in enumerate(breast_cancer.columns[1:11], start=1):\n",
    "    ax = fig.add_subplot(5,2,i)\n",
    "    sns.histplot(x=j, data=breast_cancer, hue='diagnosis', kde=True, ax=ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,15))\n",
    "benign = breast_cancer[target==0]\n",
    "malignant = breast_cancer[target==1]\n",
    "\n",
    "for i,j in enumerate(breast_cancer.columns[1:11], start=1):\n",
    "    ax = fig.add_subplot(5,2,i)\n",
    "    sns.boxplot(x=j, y='diagnosis', data=breast_cancer, ax=ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='diagnosis', data=breast_cancer, alpha=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "breast_cancer['diagnosis'] = le.fit_transform(breast_cancer['diagnosis'])\n",
    "target = le.fit_transform(target)\n",
    "target[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_corr = breast_cancer.corr()\n",
    "mask = np.zeros_like(breast_corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(breast_corr, mask=mask, cmap=\"Reds\", linewidths=0.25)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "breast_cancer.isnull().sum() # checking for missing values/null cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Data Splitting (80% Train and 20% Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, target, test_size=0.20, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Secondary Data Splitting for Validation Set in NN (60% Train and 20% Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Classifier Classification Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "# Create A Baseline using a simple rule- \n",
    "# Predict values based on distribution of training set.\n",
    "dummy = DummyClassifier(strategy='stratified')\n",
    "dummy.fit(X_train, y_train)\n",
    "y_pred_dc = dummy.predict(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_scores(y_true, y_hat):\n",
    "    c_m = confusion_matrix(y_true, y_hat)\n",
    "    acc_score = accuracy_score(y_true, y_hat)\n",
    "    roc_score = roc_auc_score(y_true, y_hat)\n",
    "    tn = c_m[0,0]\n",
    "    fn = c_m[1,0]\n",
    "    tp = c_m[1,1]\n",
    "    fp = c_m[0,1]\n",
    "    tpr = c_m[1,1]*100/np.sum(c_m[1,:])\n",
    "    tnr = c_m[0,0]*100/np.sum(c_m[0,:])\n",
    "    ppv = c_m[1,1]*100/np.sum(c_m[:,1])\n",
    "    return (acc_score, roc_score, tpr, tnr, ppv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_mat(y_true, y_hat, model):\n",
    "    c_m = confusion_matrix(y_true, y_hat)\n",
    "    print(\"Performance Metrics for: {:s}\".format(model))\n",
    "    print(\"Accuracy Score: {:.3f}\".format(accuracy_score(y_true, y_hat)))\n",
    "    print(\"Receiving Operating Characteristics Score: {:.3f}\".format(roc_auc_score(y_true, y_hat)))\n",
    "    print(\"True Negatives: {}\".format(c_m[0,0]))\n",
    "    print(\"False Negatives: {}\".format(c_m[1,0]))\n",
    "    print(\"True Positives: {}\".format(c_m[1,1]))\n",
    "    print(\"False Positives: {}\".format(c_m[0,1]))\n",
    "    print(\"TPR: {:.3f}\".format(c_m[1,1]*100/np.sum(c_m[1,:])))\n",
    "    print(\"TNR: {:.3f}\".format(c_m[0,0]*100/np.sum(c_m[0,:])))\n",
    "    print(\"PPV (Precision): {:.3f}\".format(c_m[1,1]*100/np.sum(c_m[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion Matrix for Dummy Classifier:\\n')\n",
    "print(confusion_matrix(y_test, y_pred_dc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat(y_test, y_pred_dc, 'Dummy Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification Report for Dummy Classifier:\\n')\n",
    "print(classification_report(y_test, y_pred_dc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Classification Code with TF and Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First a quick understanding of the TF library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 25\n",
    "batch_size = 20\n",
    "# convert x_test to tensor to pass through model (train data will be converted to\n",
    "# tensors on the fly)\n",
    "X_train_tf = X_train.copy()\n",
    "X_test_tf = tf.Variable(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(x_data, y_data, batch_size):\n",
    "    idxs = np.random.randint(0, len(y_data), batch_size)\n",
    "    return x_data[idxs,:], y_data[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now declare the weights connecting the input to the hidden layer\n",
    "W1 = tf.Variable(tf.random.normal([30, 15], stddev=0.03), name='W1')\n",
    "b1 = tf.Variable(tf.random.normal([15]), name='b1')\n",
    "# and the weights connecting the hidden layer to the output layer\n",
    "W2 = tf.Variable(tf.random.normal([15, 2], stddev=0.03), name='W2')\n",
    "b2 = tf.Variable(tf.random.normal([2]), name='b2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model(x_input, W1, b1, W2, b2):\n",
    "    x_input = tf.reshape(x_input, (x_input.shape[0], -1))\n",
    "    x = tf.add(tf.matmul(tf.cast(x_input, tf.float32), W1), b1)\n",
    "    x = tf.nn.relu(x)\n",
    "    logits = tf.add(tf.matmul(x, W2), b2)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(logits, labels):\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logits))\n",
    "    return cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the optimizer\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_batch = int(len(y_train)/batch_size)\n",
    "for epoch in range(epochs):\n",
    "    avg_loss = 0\n",
    "    for i in range(total_batch):\n",
    "        batch_x, batch_y = get_batch(X_train, y_train, batch_size=batch_size)\n",
    "        # create tensors\n",
    "        batch_x = tf.Variable(batch_x)\n",
    "        batch_y = tf.Variable(batch_y)\n",
    "        # create a one hot vector\n",
    "        batch_y = tf.one_hot(batch_y, 2)\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = nn_model(batch_x, W1, b1, W2, b2)\n",
    "            loss = loss_fn(logits, batch_y)\n",
    "        gradients = tape.gradient(loss, [W1, b1, W2, b2])\n",
    "        optimizer.apply_gradients(zip(gradients, [W1, b1, W2, b2]))\n",
    "        avg_loss += loss/total_batch\n",
    "    test_logits = nn_model(X_test, W1, b1, W2, b2)\n",
    "    max_idxs = tf.argmax(test_logits, axis=1)\n",
    "    test_acc = np.sum(max_idxs.numpy() == y_test)/len(y_test)\n",
    "    print('Epoch: {:d}, loss= {:.3f}, test set accuracy= {:.3f}'.format((epoch+1), (avg_loss), (test_acc*100)))\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation of actual NN Architecture with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Architecture Obtained Empirically. Start Point: Research Papers.\n",
    "\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "nn_model = Sequential()\n",
    "\n",
    "nn_model.add(Dense(30, activation='relu'))\n",
    "nn_model.add(Dropout(0.1))\n",
    "\n",
    "nn_model.add(Dense(15, activation='relu'))\n",
    "nn_model.add(Dropout(0.1))\n",
    "\n",
    "nn_model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = nn_model.fit(X_train, y_train, epochs=50, verbose=1, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_accuracy = history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_accuracy.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(loss_accuracy['loss'], 'r-', label='Training Loss')\n",
    "plt.plot(loss_accuracy['val_loss'], 'g-', label='Validation Loss')\n",
    "plt.ylabel('Training and Validation Loss')\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.title('Examining Loss Data on Neural Net Model')\n",
    "plt.legend()\n",
    "plt.tight_layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Validation Accuracy: {:.3f}, Validation Loss: {:.3f}, Validation Recall: {:.3f}'.format(\n",
    "    loss_accuracy['val_accuracy'][-1], loss_accuracy['val_loss'][-1],\\\n",
    "    loss_accuracy[list(loss_accuracy.keys())[-1]][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.evaluate(X_test,  y_test, verbose=1) # Examine testing accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.evaluate(X_train,  y_train, verbose=1) # Examine tendency to overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_nn = (nn_model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "print('Confusion Matrix for NN with TF and Keras:\\n')\n",
    "print(confusion_matrix(y_test, y_pred_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat(y_test, y_pred_nn, 'Neural Nets with TF and Keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification Report for NN with TF and Keras:\\n')\n",
    "print(classification_report(y_test, y_pred_nn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Classification Code with sklearn MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_mlp = MLPClassifier(max_iter=1000, hidden_layer_sizes= (15,1), \n",
    "                       alpha=0.001, activation='relu', solver='adam', random_state=23)\n",
    "nn_mlp.fit(X_train, y_train)\n",
    "y_pred_mlp = nn_mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conf_mat(y_test, y_pred_mlp, 'Neural Nets with MLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification Report for NN with MLP:\\n')\n",
    "print(classification_report(y_test, y_pred_mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classification Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(criterion='entropy', random_state=23)\n",
    "tree = dtc.fit(X_train, y_train)\n",
    "y_pred_dtc = dtc.predict(X_test)\n",
    "tree_plot = sklearn.tree.plot_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_text\n",
    "r = export_text(dtc, feature_names=list(features.columns))\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion Matrix for Decision Tree Classifier:\\n')\n",
    "print(confusion_matrix(y_test, y_pred_dtc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat(y_test, y_pred_dtc, 'Decision Tree Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification Report for Decision Tree Classifier:\\n')\n",
    "print(classification_report(y_test, y_pred_dtc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classification Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=128, random_state=23)\n",
    "rfc.fit(X_train, y_train)\n",
    "y_pred_rfc = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion Matrix for Random Forest Classifier:\\n')\n",
    "print(confusion_matrix(y_test, y_pred_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat(y_test, y_pred_rfc, 'Random Forest Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Classification Report for Random Forest Classifier:\\n')\n",
    "print(classification_report(y_test, y_pred_rfc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVC\n",
    "#SVC(kernel='linear')\n",
    "\n",
    "rfe_features = scaled_features.copy()\n",
    "\n",
    "# Explore the right number of features to select\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    for i in range(3, 30): # using a range of features found in various WBCD research papers\n",
    "        rfe = RFE(estimator = DecisionTreeClassifier(), n_features_to_select = i)\n",
    "        rfe.fit(rfe_features, target)\n",
    "        model = DecisionTreeClassifier()\n",
    "        models[str(i)] = Pipeline(steps=[('RFE',rfe),('DTC',model)])\n",
    "    return models\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=0)\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores\n",
    "\n",
    "models = get_models()\n",
    "\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, rfe_features, target)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('{} Accuracy: {:.3f} and Standard Deviation: {:.3f}'.format(name, np.mean(scores), np.std(scores)))\n",
    "    \n",
    "# plot model performance for comparison\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models['27'].fit(rfe_features, target)\n",
    "pipe_predict = models['27'].predict([rfe_features[0]])\n",
    "if pipe_predict == [1]:\n",
    "    print(\"Prediction is Malignant\")\n",
    "else:\n",
    "    print(\"Prediction is Benign\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic RFE using Decision Trees (RFECV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "rfecv = RFECV(estimator=DecisionTreeClassifier())\n",
    "rfecv.fit(rfe_features, target)\n",
    "model = DecisionTreeClassifier()\n",
    "pipeline_dtc = Pipeline(steps=[('RFECV',rfecv),('DTC',model)])\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=0)\n",
    "n_scores = cross_val_score(pipeline_dtc, rfe_features, target, scoring='accuracy', cv=cv,\\\n",
    "                           n_jobs=-1, error_score='raise')\n",
    "\n",
    "print('Accuracy: {:.3f} and Standard Deviation: {:.3f}'.format(np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_dtc.fit(rfe_features, target)\n",
    "pipe_predict = pipeline_dtc.predict([rfe_features[0]])\n",
    "if pipe_predict == [1]:\n",
    "    print(\"Prediction is Malignant\")\n",
    "else:\n",
    "    print(\"Prediction is Benign\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Automatically Selected Features\n",
    "for k in range(len(features.columns)):\n",
    "    print('{}, Chosen: {}, Rank: {}'.format(features.columns[k], rfecv.support_[k], rfecv.ranking_[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rfe_features = len(features.columns[rfecv.support_])\n",
    "features.columns[rfecv.support_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classification with RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame(X_train, columns=features.columns)\n",
    "X_train_rfe = np.array(X_train_df[features.columns[rfecv.support_]])\n",
    "X_val_df = pd.DataFrame(X_val, columns=features.columns)\n",
    "X_val_rfe = np.array(X_val_df[features.columns[rfecv.support_]])\n",
    "X_test_df = pd.DataFrame(X_test, columns=features.columns)\n",
    "X_test_rfe = np.array(X_test_df[features.columns[rfecv.support_]])\n",
    "\n",
    "dtc_rfe = DecisionTreeClassifier(criterion='entropy', random_state=23)\n",
    "tree_rfe = dtc_rfe.fit(X_train_rfe, y_train)\n",
    "y_pred_dtc_rfe = dtc_rfe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_text\n",
    "r = export_text(dtc_rfe, feature_names=list(features.columns[rfecv.support_]))\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion Matrix for Decision Tree Classifier with RFE:\\n')\n",
    "print(confusion_matrix(y_test, y_pred_dtc_rfe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat(y_test, y_pred_dtc_rfe, 'Decision Tree Classifier with RFE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification Report for Decision Tree Classifier with RFE:\\n')\n",
    "print(classification_report(y_test, y_pred_dtc_rfe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classification with RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_rfe = RandomForestClassifier(n_estimators=32, random_state=23)\n",
    "rfc_rfe.fit(X_train_rfe, y_train)\n",
    "y_pred_rfc_rfe = rfc_rfe.predict(X_test_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion Matrix for Random Forest Classifier:\\n')\n",
    "print(confusion_matrix(y_test, y_pred_rfc_rfe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat(y_test, y_pred_rfc_rfe, 'Random Forest Classifier with RFE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification Report for Random Forest Classifier:\\n')\n",
    "print(classification_report(y_test, y_pred_rfc_rfe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks Classification with RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_floatx('float64')\n",
    "nn_model_rfe = Sequential()\n",
    "\n",
    "nn_model_rfe.add(Dense(num_rfe_features, activation='relu'))\n",
    "nn_model_rfe.add(Dropout(0.1))\n",
    "\n",
    "nn_model_rfe.add(Dense(2, activation='relu'))\n",
    "nn_model_rfe.add(Dropout(0.1))\n",
    "\n",
    "nn_model_rfe.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model_rfe.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_rfe = nn_model_rfe.fit(X_train_rfe, y_train, epochs=50, verbose=1, validation_data=(X_val_rfe, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model_rfe.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_accuracy_rfe = history_rfe.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_accuracy_rfe.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(loss_accuracy['loss'], 'r-', label='Training Loss')\n",
    "plt.plot(loss_accuracy['val_loss'], 'g-', label='Validation Loss')\n",
    "plt.ylabel('Training and Validation Loss', fontsize=16)\n",
    "plt.xlabel('Number of Epochs', fontsize=16)\n",
    "plt.title('Examining Loss Data on Neural Net Model with RFE', fontsize=20)\n",
    "plt.legend(fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Validation Accuracy: {:.3f}, Validation Loss: {:.3f}, Validation Recall: {:.3f}'.format(\n",
    "    loss_accuracy_rfe['val_accuracy'][-1], loss_accuracy_rfe['val_loss'][-1], \\\n",
    "    loss_accuracy_rfe[list(loss_accuracy_rfe.keys())[-1]][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model_rfe.evaluate(X_test_rfe,  y_test, verbose=1) # Examine testing accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model_rfe.evaluate(X_train_rfe,  y_train, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nn_rfe = (nn_model_rfe.predict(X_test_rfe) > 0.5).astype(\"int32\")\n",
    "print('Confusion Matrix for NN with TF and RFE:\\n')\n",
    "print(confusion_matrix(y_test, y_pred_nn_rfe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat(y_test, y_pred_nn_rfe, 'Neural Nets with TF and RFE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification Report for NN with TF and RFE:\\n')\n",
    "print(classification_report(y_test, y_pred_nn_rfe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(nn_tf_acc, nn_tf_roc, nn_tf_tpr, nn_tf_tnr, nn_tf_ppv) = perf_scores(y_test, y_pred_nn)\n",
    "(dtc_acc, dtc_roc, dtc_tpr, dtc_tnr, dtc_ppv) = perf_scores(y_test, y_pred_dtc)\n",
    "(rfc_acc, rfc_roc, rfc_tpr, rfc_tnr, rfc_ppv) = perf_scores(y_test, y_pred_rfc)\n",
    "(nn_tf_rfe_acc, nn_tf_rfe_roc, nn_tf_rfe_tpr, nn_tf_rfe_tnr, nn_tf_rfe_ppv) = perf_scores(y_test, y_pred_nn_rfe)\n",
    "(dtc_rfe_acc, dtc_rfe_roc, dtc_rfe_tpr, dtc_rfe_tnr, dtc_rfe_ppv) = perf_scores(y_test, y_pred_dtc_rfe)\n",
    "(rfc_rfe_acc, rfc_rfe_roc, rfc_rfe_tpr, rfc_rfe_tnr, rfc_rfe_ppv) = perf_scores(y_test, y_pred_rfc_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['Dec_Tree_RFE', 'Rand_Forest_RFE', 'Neural_Nets_RFE', 'Decision_Tree', 'Random_Forest', 'Neural_Nets']\n",
    "test_acc = np.array([dtc_rfe_acc, rfc_rfe_acc, nn_tf_rfe_acc, dtc_acc, rfc_acc,\\\n",
    "            nn_tf_acc]).reshape(6,1)* 100\n",
    "\n",
    "model_acc = pd.DataFrame(data=test_acc, index=model_names, \n",
    "                    columns=['Testing Accuracies(%)'])\n",
    "\n",
    "fig = plt.figure(figsize=(10,4))\n",
    "ax = model_acc.plot(kind='bar', figsize=(16,8), fontsize=16, color='tab:green')\n",
    "for p in ax.patches:\n",
    "    ax.annotate(\"%.2f\" % p.get_height(), (p.get_x() + p.get_width() / 2., \n",
    "    p.get_height()),ha='center', va='center', rotation=0, xytext=(0, -20), \n",
    "    textcoords='offset points', fontsize=20, fontweight='bold', color='k')\n",
    "#ax.legend(bbox_to_anchor=(1, 1), ncol=1, fontsize=16)\n",
    "plt.ylabel('Testing Accuracies (%)', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_roc = np.array([dtc_rfe_roc, rfc_rfe_roc, nn_tf_rfe_roc, dtc_roc, rfc_roc,\\\n",
    "            nn_tf_roc]).reshape(6,1) * 100\n",
    "\n",
    "model_roc = pd.DataFrame(data=test_roc, index=model_names, \n",
    "                    columns=['Testing ROCs(%)'])\n",
    "\n",
    "fig = plt.figure(figsize=(10,4))\n",
    "ax = model_roc.plot(kind='bar', figsize=(16,8), fontsize=16, color='tab:blue')\n",
    "for p in ax.patches:\n",
    "    ax.annotate(\"%.2f\" % p.get_height(), (p.get_x() + p.get_width() / 2., \n",
    "    p.get_height()),ha='center', va='center', rotation=0, xytext=(0, -20), \n",
    "    textcoords='offset points', fontsize=20, fontweight='bold', color='k')\n",
    "#ax.legend(bbox_to_anchor=(1, 1), ncol=1, fontsize=16)\n",
    "plt.ylabel('Testing ROCs (%)', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['Dec_Tree_RFE', 'Rand_Forest_RFE', 'Neural_Nets_RFE', 'Decision_Tree', 'Random_Forest', 'Neural_Nets']\n",
    "test_tpr = np.array([dtc_rfe_tpr, rfc_rfe_tpr, nn_tf_rfe_tpr, dtc_tpr, rfc_tpr,\\\n",
    "            nn_tf_tpr]).reshape(6,1)\n",
    "\n",
    "model_tpr = pd.DataFrame(data=test_tpr, index=model_names, \n",
    "                    columns=['Testing TPR(%)'])\n",
    "\n",
    "fig = plt.figure(figsize=(10,4))\n",
    "ax = model_tpr.plot(kind='bar', figsize=(16,8), fontsize=16, color='tab:olive')\n",
    "for p in ax.patches:\n",
    "    ax.annotate(\"%.2f\" % p.get_height(), (p.get_x() + p.get_width() / 2., \n",
    "    p.get_height()),ha='center', va='center', rotation=0, xytext=(0, -20), \n",
    "    textcoords='offset points', fontsize=20, fontweight='bold', color='k')\n",
    "#ax.legend(bbox_to_anchor=(1, 1), ncol=1, fontsize=16)\n",
    "plt.ylabel('Testing TPR (%)', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_tnr = np.array([dtc_rfe_tnr, rfc_rfe_tnr, nn_tf_rfe_tnr, dtc_tnr, rfc_tnr,\\\n",
    "            nn_tf_tnr]).reshape(6,1)\n",
    "\n",
    "model_tnr = pd.DataFrame(data=test_tnr, index=model_names, \n",
    "                    columns=['Testing TNR(%)'])\n",
    "\n",
    "fig = plt.figure(figsize=(10,4))\n",
    "ax = model_tnr.plot(kind='bar', figsize=(16,8), fontsize=16, color='tab:cyan')\n",
    "for p in ax.patches:\n",
    "    ax.annotate(\"%.2f\" % p.get_height(), (p.get_x() + p.get_width() / 2., \n",
    "    p.get_height()),ha='center', va='center', rotation=0, xytext=(0, -20), \n",
    "    textcoords='offset points', fontsize=20, fontweight='bold', color='k')\n",
    "#ax.legend(bbox_to_anchor=(1, 1), ncol=1, fontsize=16)\n",
    "plt.ylabel('Testing TNR (%)', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ppv = np.array([dtc_rfe_ppv, rfc_rfe_ppv, nn_tf_rfe_ppv, dtc_ppv, rfc_ppv,\\\n",
    "            nn_tf_ppv]).reshape(6,1)\n",
    "\n",
    "model_ppv = pd.DataFrame(data=test_ppv, index=model_names, \n",
    "                    columns=['Testing PPV(%)'])\n",
    "\n",
    "fig = plt.figure(figsize=(10,4))\n",
    "ax = model_ppv.plot(kind='bar', figsize=(16,8), fontsize=16, color='tab:gray')\n",
    "for p in ax.patches:\n",
    "    ax.annotate(\"%.2f\" % p.get_height(), (p.get_x() + p.get_width() / 2., \n",
    "    p.get_height()),ha='center', va='center', rotation=0, xytext=(0, -20), \n",
    "    textcoords='offset points', fontsize=20, fontweight='bold', color='k')\n",
    "#ax.legend(bbox_to_anchor=(1, 1), ncol=1, fontsize=16)\n",
    "plt.ylabel('Testing PPV (%)', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--- {:.3f} seconds ---'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
